{
 "cells": [
  {
   "cell_type": "code",
   "id": "7fbbc7f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-04T01:54:33.586923Z",
     "start_time": "2025-05-04T01:54:32.821147Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "df = pd.read_csv(\"Stops.txt\")\n",
    "print(df.columns)\n",
    "df = df.replace({np.nan: None, \"\": None}) # Replace empty strings and NaNs with None\n",
    "\n",
    "def safe_int(val): # Needed convert certain attributes to int value required for database\n",
    "    try:\n",
    "        return int(val)\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "df['stop_code'] = df['stop_code'].apply(safe_int).astype('Int64')\n",
    "df['wheelchair_boarding'] = df['wheelchair_boarding'].apply(safe_int).astype('Int64')\n",
    "df['location_type'] = df['location_type'].apply(safe_int).astype('Int64')\n",
    "df['stop_lat'] = df['stop_lat'].astype(float)\n",
    "df['stop_lon'] = df['stop_lon'].astype(float)\n",
    "\n",
    "with open('credentials.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=config['host'],\n",
    "    database=config['database'],\n",
    "    user=config['user'],\n",
    "    password=config['password']\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    stop_id = row['stop_id']\n",
    "    values = [\n",
    "        stop_id,\n",
    "        row['stop_code'],\n",
    "        row['stop_name'],\n",
    "        row['stop_lat'],\n",
    "        row['stop_lon'],\n",
    "        row['location_type'],\n",
    "        row['parent_station'],\n",
    "        row['wheelchair_boarding'],\n",
    "        row['platform_code']\n",
    "    ]\n",
    "    values = [None if pd.isna(v) else v for v in values]\n",
    "    try:\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO gtfs_stops (stop_id, stop_code, stop_name, stop_lat, stop_lon, location_type, parent_station, wheelchair_boarding, platform_code)\n",
    "            VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s)\n",
    "            ON CONFLICT (stop_id) DO NOTHING;\n",
    "        \"\"\", values)\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting row {row}: {e}\")\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['stop_id', 'stop_code', 'stop_name', 'stop_lat', 'stop_lon',\n",
      "       'location_type', 'parent_station', 'wheelchair_boarding',\n",
      "       'platform_code'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x83 in position 69: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mUnicodeDecodeError\u001B[39m                        Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 25\u001B[39m\n\u001B[32m     22\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\u001B[33m'\u001B[39m\u001B[33mcredentials.json\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mr\u001B[39m\u001B[33m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m     23\u001B[39m     config = json.load(f)\n\u001B[32m---> \u001B[39m\u001B[32m25\u001B[39m conn = \u001B[43mpsycopg2\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     26\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhost\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mhost\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     27\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdatabase\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mdatabase\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     28\u001B[39m \u001B[43m    \u001B[49m\u001B[43muser\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43muser\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     29\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpassword\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mpassword\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[32m     30\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     31\u001B[39m cursor = conn.cursor()\n\u001B[32m     33\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m index, row \u001B[38;5;129;01min\u001B[39;00m df.iterrows():\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pythonProject\\.venv\\Lib\\site-packages\\psycopg2\\__init__.py:122\u001B[39m, in \u001B[36mconnect\u001B[39m\u001B[34m(dsn, connection_factory, cursor_factory, **kwargs)\u001B[39m\n\u001B[32m    119\u001B[39m     kwasync[\u001B[33m'\u001B[39m\u001B[33masync_\u001B[39m\u001B[33m'\u001B[39m] = kwargs.pop(\u001B[33m'\u001B[39m\u001B[33masync_\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m    121\u001B[39m dsn = _ext.make_dsn(dsn, **kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m122\u001B[39m conn = \u001B[43m_connect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdsn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconnection_factory\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconnection_factory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwasync\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    123\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m cursor_factory \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    124\u001B[39m     conn.cursor_factory = cursor_factory\n",
      "\u001B[31mUnicodeDecodeError\u001B[39m: 'utf-8' codec can't decode byte 0x83 in position 69: invalid start byte"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4bd2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def poi_in_bounding_box(xmin, ymin, xmax, ymax, filters={}):\n",
    "    baseURL = 'https://maps.six.nsw.gov.au/arcgis/rest/services/public/NSW_POI/MapServer/0/query'\n",
    "    params = {\n",
    "        'geometry': f'{xmin},{ymin},{xmax},{ymax}',\n",
    "        'geometryType': 'esriGeometryEnvelope',\n",
    "        'inSR': '4326',\n",
    "        'spatialRel': 'esriSpatialRelIntersects',\n",
    "        'outFields': '*',\n",
    "        'returnGeometry': 'true',\n",
    "        'f': 'json',\n",
    "        'where': ' AND '.join([f\"{k}='{v}'\" for k, v in filters.items()]) if filters else '1=1'\n",
    "    }\n",
    "    response = requests.get(baseURL, params=params)\n",
    "    return json.loads(response.text)['features']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd0e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sydney CBD area\n",
    "xmin, ymin, xmax, ymax = 151.2, -33.88, 151.22, -33.86\n",
    "pois = poi_in_bounding_box(xmin, ymin, xmax, ymax)\n",
    "pois\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3d6e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import time\n",
    "\n",
    "sa2 = gpd.read_file('SA2/SA2_2021_AUST_GDA2020.shp')\n",
    "selected_sa4 = 'Sydney - Blacktown'\n",
    "sa2_in_sa4 = sa2[sa2['SA4_NAME21'] == selected_sa4]\n",
    "\n",
    "pois = []\n",
    "for idx, row in sa2_in_sa4.iterrows():\n",
    "    xmin, ymin, xmax, ymax = row['geometry'].bounds  \n",
    "    pois = poi_in_bounding_box(xmin, ymin, xmax, ymax)\n",
    "\n",
    "    for poi in pois:\n",
    "        poi['SA2_NAME21'] = row['SA2_NAME21']  \n",
    "        pois.append(poi)\n",
    "    time.sleep(1)\n",
    "pois\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a874727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All POIs inserted into database.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=config['host'],\n",
    "    database=config['database'],\n",
    "    user=config['user'],\n",
    "    password=config['password']\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO PointsOfInterest (\n",
    "    objectid, topoid, poigroup, poitype, poiname, poilabel, poilabeltype, poialtlabel,\n",
    "    poisourcefeatureoid, accesscontrol, startdate, enddate, lastupdate,\n",
    "    msoid, centroidid, shapeuuid, changetype, processstate, urbanity,\n",
    "    x, y, sa2_name21\n",
    ") VALUES (\n",
    "    %(objectid)s, %(topoid)s, %(poigroup)s, %(poitype)s, %(poiname)s, %(poilabel)s, %(poilabeltype)s, %(poialtlabel)s,\n",
    "    %(poisourcefeatureoid)s, %(accesscontrol)s, %(startdate)s, %(enddate)s, %(lastupdate)s,\n",
    "    %(msoid)s, %(centroidid)s, %(shapeuuid)s, %(changetype)s, %(processstate)s, %(urbanity)s,\n",
    "    %(x)s, %(y)s, %(SA2_NAME21)s\n",
    ") ON CONFLICT (objectid) DO NOTHING;\n",
    "\"\"\" \n",
    "\n",
    "for poi in pois:\n",
    "    attributes = poi.get('attributes', {})\n",
    "    geometry = poi.get('geometry', {})\n",
    "    data = {\n",
    "        'objectid': attributes.get('objectid'),\n",
    "        'topoid': attributes.get('topoid'),\n",
    "        'poigroup': attributes.get('poigroup'),\n",
    "        'poitype': attributes.get('poitype'),\n",
    "        'poiname': attributes.get('poiname'),\n",
    "        'poilabel': attributes.get('poilabel'),\n",
    "        'poilabeltype': attributes.get('poilabeltype'),\n",
    "        'poialtlabel': attributes.get('poialtlabel'),\n",
    "        'poisourcefeatureoid': attributes.get('poisourcefeatureoid'),\n",
    "        'accesscontrol': attributes.get('accesscontrol'),\n",
    "        'startdate': attributes.get('startdate'),\n",
    "        'enddate': attributes.get('enddate'),\n",
    "        'lastupdate': attributes.get('lastupdate'),\n",
    "        'msoid': attributes.get('msoid'),\n",
    "        'centroidid': attributes.get('centroidid'),\n",
    "        'shapeuuid': attributes.get('shapeuuid'),\n",
    "        'changetype': attributes.get('changetype'),\n",
    "        'processstate': attributes.get('processstate'),\n",
    "        'urbanity': attributes.get('urbanity'),\n",
    "        'x': geometry.get('x'),\n",
    "        'y': geometry.get('y'),\n",
    "        'SA2_NAME21': poi.get('SA2_NAME21')\n",
    "    }\n",
    "    cursor.execute(insert_query, data)\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1333fd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "def load_catchments():\n",
    "    with open('config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    connection_string = f\"postgresql+psycopg2://{config['user']}:{config['password']}@{config['host']}:5432/{config['database']}\"\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    catchment = gpd.read_file('catchments/catchments_secondary.shp')\n",
    "    catchment.to_postgis(\n",
    "        name='schoolcatchments',\n",
    "        con=engine,\n",
    "        if_exists='append',\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "load_catchments() # Run this for both primary and secondary catchments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806be486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import psycopg2\n",
    "\n",
    "sa2 = gpd.read_file('SA2/SA2_2021_AUST_GDA2020.shp')\n",
    "selected_sa4 = 'Sydney - Eastern Suburbs'\n",
    "sa2_in_sa4 = sa2[sa2['SA4_NAME21'] == selected_sa4]\n",
    "\n",
    "def businesses_per_1000():\n",
    "    with open('config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    conn = psycopg2.connect(\n",
    "        host=config['host'],\n",
    "        database=config['database'],\n",
    "        user=config['user'],\n",
    "        password=config['password']\n",
    "    )\n",
    "    # Query returns SA2 names, number of businesses and number of people \n",
    "    # Condition checks for if the business is in the set of SA2 within the Eastern Suburbs\n",
    "    # Selected industry: Health Care and Social Assistance\n",
    "    query = \"\"\"\n",
    "    SELECT B.sa2_name, B.total_businesses, P.total_people\n",
    "    FROM Businesses B JOIN Population P ON B.sa2_name = P.sa2_name\n",
    "    WHERE B.sa2_name in (SELECT distinct(sa2_name21) FROM PointsOfInterest) \n",
    "    and B.industry_name = 'Health Care and Social Assistance'\n",
    "    AND P.total_people > 100;\n",
    "    \"\"\"\n",
    "    businesses = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "\n",
    "    businesses_per_1000 = {}\n",
    "    for idx, row in businesses.iterrows():\n",
    "        sa2_name = row['sa2_name']\n",
    "        total_businesses = row['total_businesses']\n",
    "        total_people = row['total_people']\n",
    "\n",
    "        per_1000 = (total_businesses / total_people) * 1000\n",
    "        businesses_per_1000[sa2_name] = per_1000\n",
    "\n",
    "    return businesses_per_1000 # returns Dictionary with key-value as sa2_name : number of businesses per 1000 people\n",
    "\n",
    "def stop_counts(sa2_in_sa4):\n",
    "    with open('config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    conn = psycopg2.connect(\n",
    "        host=config['host'],\n",
    "        database=config['database'],\n",
    "        user=config['user'],\n",
    "        password=config['password']\n",
    "    )\n",
    "    query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM gtfs_stops;\n",
    "    \"\"\"\n",
    "    stops = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "\n",
    "    stop_counts = {}\n",
    "    for idx, row in sa2_in_sa4.iterrows(): \n",
    "        sa2_name = row['SA2_NAME21']\n",
    "        stop_counts[sa2_name] = 0\n",
    "\n",
    "    for index, stop_row in stops.iterrows(): #Loops through each stop and increments the stop count of the sa2 which it belongs\n",
    "        stop_lat = stop_row['stop_lat']\n",
    "        stop_lon = stop_row['stop_lon']\n",
    "        for idx, sa2_row in sa2_in_sa4.iterrows():\n",
    "            xmin, ymin, xmax, ymax = sa2_row['geometry'].bounds  \n",
    "            if (xmin <= stop_lon <= xmax) and (ymin <= stop_lat <= ymax):\n",
    "                sa2_name = sa2_row['SA2_NAME21']\n",
    "                stop_counts[sa2_name] += 1\n",
    "                break  \n",
    "    return stop_counts # returns Dictionary with key-value as sa2_name : count\n",
    "\n",
    "def schools_per_1000(sa2_in_sa4):\n",
    "    with open('config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    conn = psycopg2.connect(\n",
    "        host=config['host'],\n",
    "        database=config['database'],\n",
    "        user=config['user'],\n",
    "        password=config['password']\n",
    "    )\n",
    "    # Query returns SA2_name and the sum of young people\n",
    "    # Only returns SA2 within Eastern suburbs \n",
    "    query = \"\"\"\n",
    "    SELECT SA2_name, \"0_4_people\" + \"5_9_people\" + \"10_14_people\" + \"15_19_people\" AS young_people\n",
    "    FROM Population P\n",
    "    WHERE sa2_name IN (\n",
    "    SELECT DISTINCT sa2_name21 FROM PointsOfInterest\n",
    "    );\n",
    "    \"\"\"\n",
    "    young_population = pd.read_sql_query(query, conn)\n",
    "    school_query = \"\"\"\n",
    "    SELECT * FROM SchoolCatchments;\n",
    "    \"\"\"\n",
    "    school = gpd.read_postgis(school_query, conn, geom_col='geometry') \n",
    "    conn.close()\n",
    "\n",
    "    school_counts = {row['SA2_NAME21']: 0 for idx, row in sa2_in_sa4.iterrows()}\n",
    "\n",
    "    for idx, school_row in school.iterrows():\n",
    "        school_geom = school_row['geometry']\n",
    "        for _, sa2_row in sa2_in_sa4.iterrows():\n",
    "            sa2_name = sa2_row['SA2_NAME21']\n",
    "            sa2_geom = sa2_row['geometry']\n",
    "\n",
    "            if school_geom.intersects(sa2_geom):\n",
    "                school_counts[sa2_name] += 1\n",
    "                break\n",
    "\n",
    "    # Merge school counts with population so we can calculate number of schools per 1000 for each sa2 \n",
    "    df = pd.DataFrame.from_dict(school_counts, orient='index', columns=['catchment_count'])\n",
    "    df.index.name = 'sa2_name'\n",
    "    df = df.reset_index()\n",
    "\n",
    "    merged = pd.merge(df, young_population, on='sa2_name')\n",
    "    merged = merged[merged['young_people'] >= 100]\n",
    "    merged['schools_per_1000'] = merged['catchment_count'] / merged['young_people'] * 1000\n",
    "\n",
    "    result = dict(zip(merged['sa2_name'], merged['schools_per_1000']))\n",
    "    return result\n",
    "\n",
    "def POI_counts():\n",
    "    with open('config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    conn = psycopg2.connect(\n",
    "        host=config['host'],\n",
    "        database=config['database'],\n",
    "        user=config['user'],\n",
    "        password=config['password']\n",
    "    )\n",
    "    # Query returns SA2_name and the number of POI\n",
    "    # Only return SA2_name in Eastern Suburbs\n",
    "    # Selected POI_Group: 1 - Civic & Community Services Police Station, Fire Station, Hospital, Library, Post Office, Gaol, Nursing Home\n",
    "    query = \"\"\"\n",
    "    SELECT sa2_name21, Count(*) as Poi_count\n",
    "    FROM PointsOfInterest\n",
    "    WHERE sa2_name21 IN (\n",
    "    SELECT DISTINCT sa2_name21 FROM PointsOfInterest\n",
    "    )\n",
    "    AND poigroup = 1\n",
    "    GROUP BY sa2_name21\n",
    "    \"\"\"\n",
    "    poi_counts = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "\n",
    "    poi_dict = dict(zip(poi_counts['sa2_name21'], poi_counts['poi_count']))\n",
    "    return poi_dict\n",
    "\n",
    "def print_dict(d):\n",
    "    for idx, (key, value) in enumerate(d.items(), start=1):\n",
    "        print(f\"{idx}. {key}: {value}\")\n",
    "    print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bcbaf7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prick\\AppData\\Local\\Temp\\ipykernel_7320\\3149492226.py:27: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  businesses_df = pd.read_sql_query(query, conn)\n",
      "C:\\Users\\prick\\AppData\\Local\\Temp\\ipykernel_7320\\3149492226.py:52: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  stops_df = pd.read_sql_query(query, conn)\n",
      "C:\\Users\\prick\\AppData\\Local\\Temp\\ipykernel_7320\\3149492226.py:85: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  young_population_df = pd.read_sql_query(query, conn)\n",
      "c:\\Users\\prick\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geopandas\\io\\sql.py:185: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\n",
      "c:\\Users\\prick\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\geopandas\\io\\sql.py:473: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return pd.read_sql(spatial_ref_sys_sql, con)\n",
      "C:\\Users\\prick\\AppData\\Local\\Temp\\ipykernel_7320\\3149492226.py:146: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  poi_counts_df = pd.read_sql_query(query, conn)\n"
     ]
    }
   ],
   "source": [
    "businesses_per_1000_people = businesses_per_1000()\n",
    "transport_stop_counts = stop_counts(sa2_in_sa4) # Will take longer than 2mins to run\n",
    "school_per_1000_people = schools_per_1000(sa2_in_sa4)\n",
    "POI = POI_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e1178692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Bondi - Tamarama - Bronte: -0.5566006147271904\n",
      "2. Bondi Beach - North Bondi: -0.7299496729491797\n",
      "3. Bondi Junction - Waverly: 2.23800214003106\n",
      "4. Dover Heights: -0.12568752500807368\n",
      "5. Paddington - Moore Park: 0.059880639815363686\n",
      "6. Rose Bay - Vaucluse - Watsons Bay: -0.05422308297250848\n",
      "7. Woollahra: 1.305567509967971\n",
      "8. Bellevue Hill: 0.3088000933814793\n",
      "9. Double Bay - Darling Point: 2.236024572442497\n",
      "10. Kensington (NSW): -0.46651742795181533\n",
      "11. Kingsford: -0.7181866721975929\n",
      "12. Maroubra - North: 0.10666027708003535\n",
      "13. Maroubra - South: -0.9834331159003482\n",
      "14. Maroubra - West: -0.7833705752282567\n",
      "15. Randwick - North: -0.4499778146531643\n",
      "16. Randwick - South: 1.26568844490545\n",
      "17. Coogee - Clovelly: -0.3023116243340851\n",
      "18. Malabar - La Perouse: -0.9839590510995185\n",
      "19. Matraville - Chifley: -1.0022306893338695\n",
      "20. South Coogee: -0.3641758112682602\n",
      "\n",
      "1. Bondi - Tamarama - Bronte: 0.9438651368592682\n",
      "2. Bondi Beach - North Bondi: 0.004143393928267247\n",
      "3. Bondi Junction - Waverly: 1.3441169903298797\n",
      "4. Centennial Park: -0.7093490405193446\n",
      "5. Dover Heights: 0.6480268103809901\n",
      "6. Paddington - Moore Park: 0.8220493553682124\n",
      "7. Rose Bay - Vaucluse - Watsons Bay: 0.8394516098669347\n",
      "8. Woollahra: -0.6745445315219001\n",
      "9. Bellevue Hill: -0.6049355135270111\n",
      "10. Double Bay - Darling Point: -1.0921986394912337\n",
      "11. Kensington (NSW): 0.26517721140910083\n",
      "12. Kingsford: -0.06546562406662171\n",
      "13. Maroubra - North: 0.6828313193784346\n",
      "14. Maroubra - South: -0.16987915105895515\n",
      "15. Maroubra - West: -0.6745445315219001\n",
      "16. Randwick - North: -0.4309129685397887\n",
      "17. Randwick - South: 0.09115466642187844\n",
      "18. Coogee - Clovelly: -0.6397400225244556\n",
      "19. Malabar - La Perouse: 2.5448725507417143\n",
      "20. Matraville - Chifley: -1.5794617654554566\n",
      "21. South Coogee: -1.544657256458012\n",
      "\n",
      "1. Bondi - Tamarama - Bronte: 2.2982568882101333\n",
      "2. Bondi Beach - North Bondi: -0.20404807491082158\n",
      "3. Bondi Junction - Waverly: 0.79406883712783\n",
      "4. Dover Heights: -0.44509083834741464\n",
      "5. Paddington - Moore Park: 1.454155428410386\n",
      "6. Rose Bay - Vaucluse - Watsons Bay: -0.9728008748828035\n",
      "7. Woollahra: -0.9728008748828035\n",
      "8. Bellevue Hill: -0.500046839642819\n",
      "9. Double Bay - Darling Point: -0.9728008748828035\n",
      "10. Kensington (NSW): 1.7161194896935936\n",
      "11. Kingsford: 0.17724862099287048\n",
      "12. Maroubra - North: 0.4490291858200933\n",
      "13. Maroubra - South: 0.9341664777258899\n",
      "14. Maroubra - West: -0.2192309427102682\n",
      "15. Randwick - North: -0.49826061532831023\n",
      "16. Randwick - South: -0.9728008748828035\n",
      "17. Coogee - Clovelly: -0.9728008748828035\n",
      "18. Malabar - La Perouse: 0.4149890554533573\n",
      "19. Matraville - Chifley: -0.5345514231977001\n",
      "20. South Coogee: -0.9728008748828035\n",
      "\n",
      "1. Dover Heights: 0.25738988591299883\n",
      "2. South Coogee: -1.3560989511535604\n",
      "3. Paddington - Moore Park: 2.178209930039855\n",
      "4. Randwick - North: -0.43410532997266943\n",
      "5. Bellevue Hill: -0.7414365370329664\n",
      "6. Rose Bay - Vaucluse - Watsons Bay: 0.7952194982685186\n",
      "7. Kingsford: -0.43410532997266943\n",
      "8. Woollahra: -0.04994132114729815\n",
      "9. Maroubra - North: 0.5647210929732959\n",
      "10. Maroubra - West: -0.7414365370329664\n",
      "11. Coogee - Clovelly: -0.587770933502818\n",
      "12. Bondi Beach - North Bondi: -0.5109381317377436\n",
      "13. Malabar - La Perouse: 1.7172131194494096\n",
      "14. Double Bay - Darling Point: -0.8182693387980406\n",
      "15. Centennial Park: -1.1256005458583376\n",
      "16. Randwick - South: -0.1267741229123724\n",
      "17. Maroubra - South: -0.9719349423281891\n",
      "18. Bondi Junction - Waverly: 1.6403803176843352\n",
      "19. Bondi - Tamarama - Bronte: 0.8720523000335928\n",
      "20. Kensington (NSW): -0.1267741229123724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def z_score(data_dict):\n",
    "    series = pd.Series(data_dict)\n",
    "    z_series = (series - series.mean()) / series.std()\n",
    "    return z_series.to_dict()\n",
    "\n",
    "print_dict(z_score(businesses_per_1000_people))\n",
    "print_dict(z_score(transport_stop_counts))\n",
    "print_dict(z_score(school_per_1000_people))\n",
    "print_dict(z_score(POI))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f3580d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Bellevue Hill: 0.17688169831006928\n",
      "2. Randwick - North: 0.14024498110595307\n",
      "3. Kingsford: 0.2610517929515383\n",
      "4. Rose Bay - Vaucluse - Watsons Bay: 0.6474038986121865\n",
      "5. Woollahra: 0.40330350266829185\n",
      "6. South Coogee: 0.014234738649420375\n",
      "7. Bondi Beach - North Bondi: 0.19142265761390542\n",
      "8. Double Bay - Darling Point: 0.3436108007793006\n",
      "9. Kensington (NSW): 0.8002735857779795\n",
      "10. Maroubra - North: 0.8585431084255251\n",
      "11. Bondi Junction - Waverly: 0.9975679076430284\n",
      "12. Maroubra - West: 0.08176661298219916\n",
      "13. Paddington - Moore Park: 0.9891673129973817\n",
      "14. Malabar - La Perouse: 0.9757103556501627\n",
      "15. Maroubra - South: 0.23306570351415054\n",
      "16. Randwick - South: 0.5639646154123281\n",
      "17. Coogee - Clovelly: 0.07567447058043619\n",
      "18. Bondi - Tamarama - Bronte: 0.9722822653505631\n",
      "19. Dover Heights: 0.5828875248490233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def Score(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def combined_resource_score(business_z, stop_z, school_z, poi_z):\n",
    "    final_scores = {}\n",
    "    all_sa2s = set(business_z) & set(stop_z) & set(school_z) & set(poi_z)\n",
    "\n",
    "    for sa2 in all_sa2s:\n",
    "        total_z = business_z[sa2] + stop_z[sa2] + school_z[sa2] + poi_z[sa2]\n",
    "        final_scores[sa2] = Score(total_z) \n",
    "        # final_scores[sa2] = round(Score(total_z), 3) if we want to round to 3 d.p\n",
    "\n",
    "    return final_scores\n",
    "\n",
    "businesses_z_score = z_score(businesses_per_1000_people)\n",
    "stops_z_score = z_score(transport_stop_counts)\n",
    "schools_z_score = z_score(school_per_1000_people)\n",
    "POI_z_score = z_score(POI)\n",
    "\n",
    "scores = combined_resource_score(businesses_z_score, stops_z_score, schools_z_score, POI_z_score)\n",
    "print_dict(scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
